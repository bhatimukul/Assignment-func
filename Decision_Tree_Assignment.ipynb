{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrXt/0ZQJOB7PyrWh0Elso",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhatimukul/Assignment-func/blob/main/Decision_Tree_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Theoretical***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Gb-uV0mKOeeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1.What is a Decision Tree, and how does it work?"
      ],
      "metadata": {
        "id": "ujygXdjoO2nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.A **Decision Tree** is a supervised machine learning algorithm used for classification and regression tasks. It models decisions using a tree-like structure, where each internal node represents a decision based on a feature, each branch represents an outcome, and each leaf node represents a final classification or prediction.\n",
        "\n",
        "### **How Does a Decision Tree Work?**\n",
        "1. **Start with the Root Node:**  \n",
        "   - The algorithm selects the best feature (attribute) to split the data based on criteria like **Gini Impurity**, **Entropy (Information Gain)**, or **Mean Squared Error (for regression).**\n",
        "\n",
        "2. **Recursive Splitting:**  \n",
        "   - The dataset is divided into subsets based on feature values.\n",
        "   - The process continues recursively, creating child nodes.\n",
        "\n",
        "3. **Stopping Criteria:**  \n",
        "   - Splitting stops when:\n",
        "     - A node becomes pure (all samples belong to one class).\n",
        "     - A maximum depth is reached.\n",
        "     - Further splitting does not improve results significantly.\n",
        "\n",
        "4. **Prediction:**  \n",
        "   - For classification: A sample follows the path in the tree until it reaches a leaf node, which gives the predicted class.\n",
        "   - For regression: The average value of samples in a leaf node is used as the prediction.\n",
        "\n",
        "### **Advantages of Decision Trees:**\n",
        "‚úîÔ∏è Easy to understand and interpret  \n",
        "‚úîÔ∏è Requires minimal data preprocessing  \n",
        "‚úîÔ∏è Handles both numerical and categorical data  \n",
        "‚úîÔ∏è Works well with large datasets  \n",
        "\n",
        "### **Disadvantages:**\n",
        "‚ùå Prone to overfitting (can create very complex trees)  \n",
        "‚ùå Sensitive to small variations in data  \n",
        "‚ùå May not generalize well without pruning or setting depth limits  \n",
        "\n",
        "### **Common Variants:**\n",
        "- **Random Forest**: An ensemble of multiple decision trees to improve accuracy.\n",
        "- **Gradient Boosting Trees (XGBoost, LightGBM, etc.)**: A sequential method improving weak trees iteratively.\n"
      ],
      "metadata": {
        "id": "IXqEi78mO8Lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.What are impurity measures in Decision Trees?"
      ],
      "metadata": {
        "id": "6OAp9SEQPEoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **Impurity Measures in Decision Trees**\n",
        "Impurity measures determine how \"pure\" or \"impure\" a node is in a Decision Tree. A node is **pure** if all its samples belong to a single class (for classification) or have similar values (for regression). Impurity measures help decide the best feature for splitting the data.\n",
        "\n",
        "### **1. Gini Impurity (for Classification)**\n",
        "Gini Impurity measures the probability of misclassifying a randomly chosen sample.\n",
        "\n",
        "\\[\n",
        "Gini = 1 - \\sum_{i=1}^{C} p_i^2\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( C \\) is the number of classes  \n",
        "- \\( p_i \\) is the probability of a sample belonging to class \\( i \\)  \n",
        "\n",
        "‚úî **Range:** 0 (pure) to 0.5 (most impure with two classes)  \n",
        "‚úî **Lower values are better (indicating higher purity).**  \n",
        "\n",
        "### **2. Entropy (Information Gain) (for Classification)**\n",
        "Entropy measures the amount of randomness (or disorder) in a node.\n",
        "\n",
        "\\[\n",
        "Entropy = -\\sum_{i=1}^{C} p_i \\log_2(p_i)\n",
        "\\]\n",
        "\n",
        "- If all samples belong to one class ‚Üí Entropy = 0 (pure node).  \n",
        "- If classes are equally distributed ‚Üí Entropy is maximum.  \n",
        "- **Information Gain** = Reduction in entropy after a split.\n",
        "\n",
        "‚úî **Lower entropy means a better split**  \n",
        "‚úî **Used in ID3 and C4.5 algorithms**  \n",
        "\n",
        "### **3. Mean Squared Error (MSE) (for Regression)**\n",
        "For regression trees, impurity is measured using **MSE**, which calculates the variance within a node.\n",
        "\n",
        "\\[\n",
        "MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\bar{y})^2\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( y_i \\) are the target values  \n",
        "- \\( \\bar{y} \\) is the mean target value of the node  \n",
        "\n",
        "‚úî **Lower MSE indicates better homogeneity in a node.**  \n",
        "\n",
        "### **4. Mean Absolute Error (MAE) (for Regression)**\n",
        "Instead of squaring errors like MSE, MAE takes the absolute difference:\n",
        "\n",
        "\\[\n",
        "MAE = \\frac{1}{N} \\sum_{i=1}^{N} |y_i - \\bar{y}|\n",
        "\\]\n",
        "\n",
        "‚úî **Less sensitive to outliers than MSE**  \n",
        "‚úî **Not as commonly used in Decision Trees as MSE**  \n",
        "\n",
        "### **Which Impurity Measure to Use?**\n",
        "- **Gini Impurity** ‚Üí Faster computation, used in **CART (Classification and Regression Trees)**.\n",
        "- **Entropy** ‚Üí More informative, used in **ID3 and C4.5 algorithms**.\n",
        "- **MSE/MAE** ‚Üí Used for regression problems.\n"
      ],
      "metadata": {
        "id": "99K83bclPJJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3.What is the mathematical formula for Gini Impurity?"
      ],
      "metadata": {
        "id": "zz2tDzkDPSsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.The mathematical formula for **Gini Impurity** is:\n",
        "\n",
        "\\[\n",
        "Gini = 1 - \\sum_{i=1}^{C} p_i^2\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( C \\) is the total number of classes.  \n",
        "- \\( p_i \\) is the probability of a randomly chosen sample belonging to class \\( i \\).  \n",
        "\n",
        "### **Explanation:**\n",
        "- Gini Impurity measures the probability of **misclassifying** a randomly chosen sample if it is labeled according to the class distribution in the node.\n",
        "- If all samples in a node belong to one class (\\( p_i = 1 \\)), then **Gini = 0** (pure node).\n",
        "- If classes are equally distributed (\\( p_i = 0.5 \\) for two classes), then **Gini = 0.5** (maximum impurity for binary classification).\n",
        "\n",
        "### **Example Calculation:**\n",
        "Suppose a node has 10 samples:\n",
        "- 6 belong to **Class A** ‚Üí \\( p_A = \\frac{6}{10} = 0.6 \\)\n",
        "- 4 belong to **Class B** ‚Üí \\( p_B = \\frac{4}{10} = 0.4 \\)\n",
        "\n",
        "\\[\n",
        "Gini = 1 - (0.6^2 + 0.4^2)\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "Gini = 1 - (0.36 + 0.16) = 1 - 0.52 = 0.48\n",
        "\\"
      ],
      "metadata": {
        "id": "QwkfiTDLPWsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4.What is the mathematical formula for Entropy?"
      ],
      "metadata": {
        "id": "YHobEN46P5tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.The mathematical formula for **Entropy** in a Decision Tree is:\n",
        "\n",
        "\\[\n",
        "Entropy = -\\sum_{i=1}^{C} p_i \\log_2(p_i)\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( C \\) is the total number of classes.  \n",
        "- \\( p_i \\) is the probability of a randomly chosen sample belonging to class \\( i \\).  \n",
        "- \\( \\log_2 \\) is the logarithm base 2.\n",
        "\n",
        "### **Explanation:**\n",
        "- Entropy measures the amount of **uncertainty** (or disorder) in a node.\n",
        "- **Lower entropy** ‚Üí More pure node (better split).\n",
        "- **Higher entropy** ‚Üí More mixed classes (worse split).\n",
        "\n",
        "### **Entropy Values:**\n",
        "- **If a node is pure** (all samples belong to one class), then \\( p_i = 1 \\), so:\n",
        "\n",
        "  \\[\n",
        "  Entropy = - (1 \\cdot \\log_2 1) = 0\n",
        "  \\]\n",
        "\n",
        "- **If two classes are equally distributed** (\\( p_1 = 0.5 \\), \\( p_2 = 0.5 \\)):\n",
        "\n",
        "  \\[\n",
        "  Entropy = - (0.5 \\log_2 0.5 + 0.5 \\log_2 0.5)\n",
        "  \\]\n",
        "\n",
        "  \\[\n",
        "  = - (0.5 \\times -1 + 0.5 \\times -1) = 1\n",
        "  \\]\n",
        "\n",
        "  This is the **maximum entropy** for a binary classification.\n",
        "\n",
        "### **Example Calculation:**\n",
        "If a node has 10 samples:\n",
        "- 7 belong to **Class A** ‚Üí \\( p_A = \\frac{7}{10} = 0.7 \\)\n",
        "- 3 belong to **Class B** ‚Üí \\( p_B = \\frac{3}{10} = 0.3 \\)\n",
        "\n",
        "\\[\n",
        "Entropy = - (0.7 \\log_2 0.7 + 0.3 \\log_2 0.3)\n",
        "\\]\n",
        "\n",
        "Approximating log values:\n",
        "\n",
        "\\[\n",
        "= - (0.7 \\times (-0.514) + 0.3 \\times (-1.737))\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "= - (-0.3598 - 0.5211) = 0.881\n",
        "\\]\n"
      ],
      "metadata": {
        "id": "HkH-xNV_P-ns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What is Information Gain, and how is it used in Decision Trees?"
      ],
      "metadata": {
        "id": "lsdzeNpLRrts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **What is Information Gain?**  \n",
        "**Information Gain (IG)** is a measure used in decision trees to determine the best feature to split the data. It quantifies how much uncertainty (entropy) is reduced after a split.\n",
        "\n",
        "### **Mathematical Formula:**\n",
        "\\[\n",
        "IG = Entropy(Parent) - \\sum_{i=1}^{k} \\frac{N_i}{N} \\cdot Entropy(Child_i)\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( Entropy(Parent) \\) = Entropy before the split.  \n",
        "- \\( k \\) = Number of child nodes after the split.  \n",
        "- \\( N_i \\) = Number of samples in child node \\( i \\).  \n",
        "- \\( N \\) = Total number of samples in the parent node.  \n",
        "- \\( Entropy(Child_i) \\) = Entropy of the \\( i \\)th child node.  \n",
        "\n",
        "### **How is Information Gain Used in Decision Trees?**  \n",
        "1. **Calculate the Entropy of the Parent Node** (before the split).  \n",
        "2. **Split the data** based on a feature.  \n",
        "3. **Compute the weighted entropy** of the child nodes.  \n",
        "4. **Calculate Information Gain** using the formula.  \n",
        "5. **Choose the feature with the highest IG** for splitting the node.  \n",
        "\n",
        "### **Example Calculation:**\n",
        "Suppose a dataset has 10 samples:\n",
        "- **Before Split:** 6 Class A, 4 Class B ‚Üí \\( Entropy_{parent} = 0.971 \\)\n",
        "- **After Split:**\n",
        "  - **Left Node (4 samples):** 3 Class A, 1 Class B ‚Üí \\( Entropy_{left} = 0.811 \\)\n",
        "  - **Right Node (6 samples):** 3 Class A, 3 Class B ‚Üí \\( Entropy_{right} = 1.000 \\)\n",
        "\n",
        "\\[\n",
        "IG = 0.971 - \\left(\\frac{4}{10} \\times 0.811 + \\frac{6}{10} \\times 1.000\\right)\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "IG = 0.971 - (0.324 + 0.6) = 0.971 - 0.924 = 0.047\n",
        "\\]\n",
        "\n",
        "A higher **IG** means a better split, leading to a purer node.\n"
      ],
      "metadata": {
        "id": "r9C3m0clRxE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6.What is the difference between Gini Impurity and Entropy?"
      ],
      "metadata": {
        "id": "MOGeC61mR743"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **Difference Between Gini Impurity and Entropy**\n",
        "\n",
        "| **Criteria**        | **Gini Impurity**                                      | **Entropy**                                            |\n",
        "|--------------------|------------------------------------------------------|------------------------------------------------------|\n",
        "| **Formula**       | \\( Gini = 1 - \\sum p_i^2 \\)                          | \\( Entropy = -\\sum p_i \\log_2 p_i \\)                |\n",
        "| **Range**         | 0 (pure) to 0.5 (for binary classification)          | 0 (pure) to 1 (for binary classification)          |\n",
        "| **Meaning**       | Measures the **probability of misclassification** if randomly chosen. | Measures the **degree of uncertainty (disorder)** in a node. |\n",
        "| **Computation**   | Easier to compute (does not involve logarithms).      | More computationally expensive (involves logarithms). |\n",
        "| **Splitting Behavior** | Tends to create **larger partitions** and is biased toward pure splits. | Can create **more balanced splits** (may not always be optimal). |\n",
        "| **Usage**        | Used in **CART (Classification and Regression Trees)**. | Used in **ID3, C4.5, and C5.0 Decision Trees**. |\n",
        "\n",
        "### **When to Use What?**\n",
        "- **Use Gini Impurity** when you want **faster calculations** and simpler trees.\n",
        "- **Use Entropy** when you want a **more information-theoretic approach** (reducing uncertainty more precisely).\n",
        "\n",
        "### **Example Comparison:**\n",
        "Suppose a node has:\n",
        "- **70% Class A** (\\( p_A = 0.7 \\))\n",
        "- **30% Class B** (\\( p_B = 0.3 \\))\n",
        "\n",
        "#### **Gini Impurity Calculation**\n",
        "\\[\n",
        "Gini = 1 - (0.7^2 + 0.3^2)\n",
        "\\]\n",
        "\\[\n",
        "= 1 - (0.49 + 0.09) = 0.42\n",
        "\\]\n",
        "\n",
        "#### **Entropy Calculation**\n",
        "\\[\n",
        "Entropy = - (0.7 \\log_2 0.7 + 0.3 \\log_2 0.3)\n",
        "\\]\n",
        "Approximating logs:\n",
        "\\[\n",
        "= - (0.7 \\times -0.514 + 0.3 \\times -1.737)\n",
        "\\]\n",
        "\\[\n",
        "= - (-0.36 - 0.52) = 0.88\n",
        "\\]\n",
        "\n",
        "Here, Entropy is higher than Gini, indicating more disorder.\n"
      ],
      "metadata": {
        "id": "I0ESQQwPSDnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7.What is the mathematical explanation behind Decision Trees?"
      ],
      "metadata": {
        "id": "b-ficauoSMuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **Mathematical Explanation Behind Decision Trees**\n",
        "Decision Trees use recursive partitioning (also called **divide-and-conquer**) to split data into smaller subsets until a stopping criterion is met. This process is guided by impurity measures and optimization functions.\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Splitting Criterion (Choosing the Best Feature)**\n",
        "At each step, the algorithm selects the feature that best separates the data. This is determined using **impurity measures** like:\n",
        "- **Gini Impurity** (CART algorithm)\n",
        "- **Entropy & Information Gain** (ID3, C4.5)\n",
        "\n",
        "### **Mathematical Formulation:**\n",
        "The **best split** is the one that minimizes impurity.\n",
        "\n",
        "#### **Gini Impurity Formula:**\n",
        "\\[\n",
        "Gini = 1 - \\sum_{i=1}^{C} p_i^2\n",
        "\\]\n",
        "\n",
        "#### **Entropy Formula:**\n",
        "\\[\n",
        "Entropy = -\\sum_{i=1}^{C} p_i \\log_2(p_i)\n",
        "\\]\n",
        "\n",
        "#### **Information Gain Formula:**\n",
        "\\[\n",
        "IG = Entropy(Parent) - \\sum_{i=1}^{k} \\frac{N_i}{N} \\cdot Entropy(Child_i)\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( p_i \\) = Probability of class \\( i \\) in a node  \n",
        "- \\( C \\) = Number of classes  \n",
        "- \\( N_i \\) = Samples in child node \\( i \\)  \n",
        "- \\( N \\) = Total samples in the parent node  \n",
        "\n",
        "---\n",
        "\n",
        "## **2. Recursive Splitting (Tree Construction)**\n",
        "The algorithm **recursively** selects features and splits the data until a stopping condition is met.\n",
        "\n",
        "\\[\n",
        "\\text{Stop if:}\n",
        "\\]\n",
        "- A node becomes **pure** (all samples belong to one class).\n",
        "- A **maximum depth** is reached.\n",
        "- The **number of samples in a node** is below a threshold.\n",
        "\n",
        "Each split **reduces impurity**, ensuring a well-structured tree.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Prediction in a Decision Tree**\n",
        "To classify a new data point:\n",
        "- Start at the **root**.\n",
        "- Traverse the tree by **following conditions** at each node.\n",
        "- Reach a **leaf node**, which determines the predicted class.\n",
        "\n",
        "For **regression**, instead of classification, the leaf node returns the **average target value**.\n",
        "\n",
        "\\[\n",
        "y_{predicted} = \\frac{1}{N} \\sum_{i=1}^{N} y_i\n",
        "\\]\n",
        "\n",
        "Where \\( y_i \\) are the target values in the leaf node.\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Tree Pruning (Avoiding Overfitting)**\n",
        "A fully grown tree might **overfit**, capturing noise in the data. **Pruning** reduces complexity:\n",
        "- **Pre-pruning:** Stop splitting early (e.g., max depth).\n",
        "- **Post-pruning:** Grow a full tree, then remove branches based on a threshold.\n",
        "\n",
        "A common post-pruning technique is **Cost Complexity Pruning**, where a penalty term \\( \\alpha \\) is added to prevent excessive growth:\n",
        "\n",
        "\\[\n",
        "\\text{Pruned Loss} = \\text{Tree Impurity} + \\alpha \\times (\\text{Number of leaves})\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "## **Summary**\n",
        "1. **Select the best feature** using Gini Impurity or Information Gain.\n",
        "2. **Recursively split** the dataset to reduce impurity.\n",
        "3. **Stop splitting** when purity is reached or stopping conditions are met.\n",
        "4. **Make predictions** by traversing the tree to a leaf node.\n",
        "5. **Prune the tree** to prevent overfitting.\n"
      ],
      "metadata": {
        "id": "161NBzY-STAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8.What is Pre-Pruning in Decision Trees?"
      ],
      "metadata": {
        "id": "Ml2maII3SfsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **Pre-Pruning in Decision Trees**\n",
        "**Pre-pruning** (also called **early stopping**) is a technique used to prevent a Decision Tree from growing too large and overfitting the training data by stopping the tree-building process **before** it becomes too complex.\n",
        "\n",
        "---\n",
        "\n",
        "### **How Pre-Pruning Works**\n",
        "During tree construction, the algorithm checks certain stopping conditions **before** creating new splits. If any condition is met, the splitting stops, and the node becomes a leaf.\n",
        "\n",
        "### **Common Pre-Pruning Conditions**\n",
        "1. **Maximum Depth (\\( d_{max} \\))**  \n",
        "   - Limit the depth of the tree.\n",
        "   - Example: If \\( d_{max} = 5 \\), the tree stops splitting beyond level 5.\n",
        "\n",
        "2. **Minimum Samples per Leaf (\\( n_{min} \\))**  \n",
        "   - A node must have at least \\( n_{min} \\) samples to be split further.\n",
        "   - Example: If \\( n_{min} = 10 \\), any node with fewer than 10 samples will not split.\n",
        "\n",
        "3. **Minimum Information Gain (\\( IG_{min} \\))**  \n",
        "   - Stop splitting if the improvement in Information Gain (or Gini reduction) is below a threshold.\n",
        "   - Example: If \\( IG_{min} = 0.01 \\), and a split improves IG by only 0.005, the split is rejected.\n",
        "\n",
        "4. **Maximum Number of Nodes (\\( N_{max} \\))**  \n",
        "   - Restrict the total number of nodes in the tree.\n",
        "\n",
        "---\n",
        "\n",
        "### **Advantages of Pre-Pruning**\n",
        "‚úî Prevents overfitting by limiting tree complexity.  \n",
        "‚úî Reduces computation time.  \n",
        "‚úî Produces simpler, more interpretable trees.  \n",
        "\n",
        "### **Disadvantages of Pre-Pruning**\n",
        "‚ùå May stop the tree **too early**, leading to **underfitting** (not capturing enough patterns).  \n",
        "‚ùå Choosing the best pre-pruning thresholds is difficult and dataset-dependent.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Example: Pre-Pruning in Scikit-Learn (Python)**\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Decision tree with pre-pruning: max depth and min samples per leaf\n",
        "tree = DecisionTreeClassifier(max_depth=5, min_samples_leaf=10)\n",
        "\n",
        "# Fit the model\n",
        "tree.fit(X_train, y_train)\n",
        "```\n",
        "Here, the tree stops growing beyond depth **5** and does not create splits if a node has fewer than **10 samples**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "8g1NjWoBSlME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is Post-Pruning in Decision Trees?"
      ],
      "metadata": {
        "id": "HQ70TM6HS58A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **Post-Pruning in Decision Trees**  \n",
        "**Post-pruning** (also called **pruning** or **cost-complexity pruning**) is a technique used to **reduce** the size of an already fully grown Decision Tree to prevent overfitting. It works by **removing branches** that provide little predictive power.\n",
        "\n",
        "---\n",
        "\n",
        "### **How Post-Pruning Works**  \n",
        "1. **Grow a full Decision Tree** (without restrictions like depth or minimum samples).  \n",
        "2. **Evaluate the tree‚Äôs performance** on a validation set.  \n",
        "3. **Remove weak branches** (those that do not significantly improve accuracy).  \n",
        "4. **Repeat the process** until the optimal tree is found.\n",
        "\n",
        "---\n",
        "\n",
        "### **Types of Post-Pruning**\n",
        "1. **Cost Complexity Pruning (CCP)** (*used in CART algorithm*)  \n",
        "   - Uses a penalty term \\( \\alpha \\) to control complexity:\n",
        "     \\[\n",
        "     Loss = \\text{Tree Impurity} + \\alpha \\times (\\text{Number of Leaves})\n",
        "     \\]\n",
        "   - Higher \\( \\alpha \\) leads to **more pruning**.\n",
        "\n",
        "2. **Reduced Error Pruning (REP)**  \n",
        "   - Each non-leaf node is temporarily replaced with a leaf.  \n",
        "   - If performance **improves or remains the same**, the branch is removed.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Advantages of Post-Pruning**\n",
        "‚úî **Reduces overfitting**, making the tree generalize better.  \n",
        "‚úî **Improves interpretability** by simplifying the tree.  \n",
        "‚úî **Data-driven approach**, based on actual model performance.  \n",
        "\n",
        "### **Disadvantages of Post-Pruning**\n",
        "‚ùå **Computationally expensive** (requires evaluating multiple subtrees).  \n",
        "‚ùå May **remove useful splits** if not tuned properly.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Example: Post-Pruning in Scikit-Learn (Python)**\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train an overgrown tree\n",
        "tree = DecisionTreeClassifier(ccp_alpha=0.01)  # Post-pruning using cost complexity\n",
        "tree.fit(X_train, y_train)\n",
        "```\n",
        "Here, **`ccp_alpha`** controls pruning strength. A higher value leads to **more pruning**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Pre-Pruning vs. Post-Pruning**\n",
        "| Feature        | Pre-Pruning | Post-Pruning |\n",
        "|---------------|------------|--------------|\n",
        "| **When Applied?** | During training (stops early) | After training (removes branches) |\n",
        "| **Prevents Overfitting?** | Yes, but may cause underfitting | Yes, more effective |\n",
        "| **Computational Cost** | Lower | Higher (requires validation) |\n",
        "| **Best for?** | Avoiding excessive tree growth | Optimizing an existing tree |\n"
      ],
      "metadata": {
        "id": "qlsBrXj1S93G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10.What is the difference between Pre-Pruning and Post-Pruning?"
      ],
      "metadata": {
        "id": "2toWX-W7TI8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **Difference Between Pre-Pruning and Post-Pruning in Decision Trees**\n",
        "\n",
        "| **Feature**        | **Pre-Pruning** (Early Stopping) | **Post-Pruning** (Pruning After Training) |\n",
        "|--------------------|---------------------------------|----------------------------------|\n",
        "| **When Applied?**  | During tree growth (before fully developing the tree). | After the tree is fully grown. |\n",
        "| **How It Works?**  | Stops tree expansion when a condition is met (e.g., max depth, min samples). | Grows a large tree first, then removes unnecessary branches. |\n",
        "| **Prevents Overfitting?** | Yes, but may cause underfitting if stopped too early. | Yes, more effective as it evaluates splits before removing them. |\n",
        "| **Computational Cost** | Lower (faster training). | Higher (needs extra validation step). |\n",
        "| **Common Stopping Criteria** | - Max depth (\\(d_{max}\\))  <br> - Min samples per leaf (\\(n_{min}\\)) <br> - Min information gain (\\(IG_{min}\\)) | - Cost Complexity Pruning (CCP) <br> - Reduced Error Pruning (REP) |\n",
        "| **Risk of Underfitting?** | High (may stop before finding the best splits). | Low (tree has been fully trained before pruning). |\n",
        "| **Best Use Case** | When training time is a concern or when preventing large trees. | When accuracy is more important, and overfitting is a concern. |\n",
        "\n",
        "---\n",
        "\n",
        "### **Example in Python (Scikit-Learn)**\n",
        "\n",
        "#### **Pre-Pruning Example**\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Pre-pruned tree with max depth and min samples per leaf\n",
        "tree = DecisionTreeClassifier(max_depth=5, min_samples_leaf=10)\n",
        "tree.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "#### **Post-Pruning Example**\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train a full tree first\n",
        "full_tree = DecisionTreeClassifier(random_state=42)\n",
        "full_tree.fit(X_train, y_train)\n",
        "\n",
        "# Apply Cost Complexity Pruning (select best alpha)\n",
        "path = full_tree.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "\n",
        "# Train pruned trees for different alpha values and choose the best one\n",
        "pruned_tree = DecisionTreeClassifier(ccp_alpha=ccp_alphas[5])\n",
        "pruned_tree.fit(X_train, y_train)\n",
        "```"
      ],
      "metadata": {
        "id": "f9N4XSrxTQAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11.What is a Decision Tree Regressor?"
      ],
      "metadata": {
        "id": "IAgrcUYVTc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **Decision Tree Regressor: An Overview**  \n",
        "A **Decision Tree Regressor** is a type of **Decision Tree algorithm used for regression tasks**, meaning it predicts continuous numerical values instead of discrete classes.\n",
        "\n",
        "---\n",
        "\n",
        "## **How It Works**\n",
        "1. **Splitting the Data**  \n",
        "   - The dataset is recursively split into subsets based on **feature values**.\n",
        "   - Instead of **classification impurity measures** (Gini or Entropy), it uses **variance reduction** or **mean squared error (MSE)** as the splitting criterion.\n",
        "\n",
        "2. **Leaf Node Output**  \n",
        "   - Instead of assigning a class label, a leaf node in a Decision Tree Regressor **predicts a numerical value**, usually the **mean of the target values** in that region.\n",
        "\n",
        "---\n",
        "\n",
        "## **Mathematical Formulation**\n",
        "The tree tries to **minimize the variance** (or MSE) within each split.\n",
        "\n",
        "### **Split Selection: Minimizing Variance**\n",
        "At each step, the algorithm selects the split that minimizes the weighted sum of variances:\n",
        "\n",
        "\\[\n",
        "Var_{split} = \\frac{N_{left}}{N} \\cdot Var_{left} + \\frac{N_{right}}{N} \\cdot Var_{right}\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( Var_{split} \\) = Variance after splitting.  \n",
        "- \\( N_{left}, N_{right} \\) = Number of samples in left and right nodes.  \n",
        "- \\( Var_{left}, Var_{right} \\) = Variance of target values in left and right nodes.  \n",
        "- \\( N \\) = Total number of samples before the split.\n",
        "\n",
        "The goal is to **minimize** \\( Var_{split} \\), ensuring that each split reduces the spread of the target variable.\n",
        "\n",
        "### **Alternative Criterion: Mean Squared Error (MSE)**\n",
        "A common impurity measure for regression is **MSE**, which calculates the error in predictions:\n",
        "\n",
        "\\[\n",
        "MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y})^2\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( y_i \\) = Actual target value.  \n",
        "- \\( \\hat{y} \\) = Predicted value (mean of leaf node).  \n",
        "- \\( N \\) = Number of samples in the node.\n",
        "\n",
        "---\n",
        "\n",
        "## **Example: Decision Tree Regressor in Python**\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import numpy as np\n",
        "\n",
        "# Sample Data\n",
        "X = np.array([[1], [2], [3], [4], [5], [6]]).reshape(-1, 1)\n",
        "y = np.array([10, 20, 30, 40, 50, 60])\n",
        "\n",
        "# Train Decision Tree Regressor\n",
        "tree = DecisionTreeRegressor(max_depth=3)\n",
        "tree.fit(X, y)\n",
        "\n",
        "# Predict a new value\n",
        "prediction = tree.predict([[3.5]])\n",
        "print(\"Predicted Value:\", prediction)\n",
        "```\n",
        "---\n",
        "\n",
        "## **Advantages**\n",
        "‚úî **Captures non-linear relationships** between features and target values.  \n",
        "‚úî **Handles missing values** and does not require feature scaling.  \n",
        "‚úî **Interpretable** (easy to visualize as a decision tree).  \n",
        "\n",
        "## **Disadvantages**\n",
        "‚ùå **Prone to overfitting** if the tree is too deep.  \n",
        "‚ùå **Sensitive to small changes** in data (leading to different trees).  \n",
        "‚ùå **Not smooth** (predictions are piecewise constant, causing sharp transitions).  \n",
        "\n",
        "---\n",
        "\n",
        "## **When to Use Decision Tree Regression**\n",
        "‚úÖ When relationships between features and target are **non-linear**.  \n",
        "‚úÖ When interpretability is important.  \n",
        "‚úÖ When feature scaling is not ideal (Decision Trees don‚Äôt require standardization).  \n"
      ],
      "metadata": {
        "id": "9egs5KixTjV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12.* What are the advantages and disadvantages of Decision Trees?"
      ],
      "metadata": {
        "id": "k1V3wQ1RTvbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **Advantages and Disadvantages of Decision Trees**  \n",
        "\n",
        "---\n",
        "\n",
        "## **‚úÖ Advantages of Decision Trees**  \n",
        "\n",
        "### **1. Easy to Understand and Interpret**  \n",
        "- Decision Trees provide **clear visual representations** of decision-making.\n",
        "- Even non-experts can understand how the model makes predictions.\n",
        "\n",
        "### **2. Handles Both Numerical and Categorical Data**  \n",
        "- Works well for both **classification** and **regression** problems.\n",
        "- No need for extensive **data preprocessing** (like feature scaling).\n",
        "\n",
        "### **3. No Need for Feature Scaling or Normalization**  \n",
        "- Unlike models like SVM or Logistic Regression, Decision Trees don‚Äôt require feature scaling (e.g., Standardization or Min-Max scaling).\n",
        "\n",
        "### **4. Handles Missing Values Well**  \n",
        "- Can still make reasonable predictions even with **incomplete data**.\n",
        "\n",
        "### **5. Captures Non-Linear Relationships**  \n",
        "- Unlike linear models, Decision Trees can model **complex, non-linear** patterns.\n",
        "\n",
        "### **6. Feature Selection is Automatic**  \n",
        "- The tree **automatically selects the most important features** while splitting.\n",
        "\n",
        "### **7. Works Well with Large Datasets**  \n",
        "- Can handle high-dimensional data efficiently.\n",
        "\n",
        "---\n",
        "\n",
        "## **‚ùå Disadvantages of Decision Trees**  \n",
        "\n",
        "### **1. Prone to Overfitting**  \n",
        "- Deep trees **memorize training data** rather than generalizing well.\n",
        "- Solution: **Use pruning techniques** (Pre-Pruning, Post-Pruning).\n",
        "\n",
        "### **2. Sensitive to Small Changes in Data**  \n",
        "- Small variations in data can create **entirely different trees**.\n",
        "- Solution: Use **ensemble methods** like **Random Forests**.\n",
        "\n",
        "### **3. Greedy Algorithm (Locally Optimal, Not Globally Optimal)**  \n",
        "- The tree makes decisions **greedily at each step**, which may not lead to the **best overall structure**.\n",
        "- Solution: **Use hyperparameter tuning** to refine splits.\n",
        "\n",
        "### **4. Not Suitable for Continuous, Smooth Predictions (Regression)**  \n",
        "- Decision Trees predict **stepwise constant values** in regression tasks, leading to **jumpy predictions**.\n",
        "- Solution: Use **ensemble methods** like **Gradient Boosting**.\n",
        "\n",
        "### **5. Biased Towards Features with More Categories**  \n",
        "- Features with **many unique values** (like ID numbers) might be given too much importance.\n",
        "- Solution: Use **entropy-based splitting (Information Gain Ratio)**.\n",
        "\n",
        "---\n",
        "\n",
        "### **How to Overcome Decision Tree Limitations?**  \n",
        "‚úÖ **Pruning** (Pre-Pruning or Post-Pruning) ‚Üí Reduces Overfitting.  \n",
        "‚úÖ **Random Forest** ‚Üí Reduces variance and improves stability.  \n",
        "‚úÖ **Boosting (Gradient Boosting, XGBoost)** ‚Üí Improves accuracy.  \n",
        "‚úÖ **Hyperparameter Tuning** (max depth, min samples split) ‚Üí Optimizes tree structure.  \n"
      ],
      "metadata": {
        "id": "PPxwEQ3aT1ob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13.* How does a Decision Tree handle missing values?"
      ],
      "metadata": {
        "id": "WIysUBtMUABb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **How Decision Trees Handle Missing Values**  \n",
        "\n",
        "Decision Trees are quite robust to **missing values** in both training and prediction phases. They can handle missing data in the following ways:\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Handling Missing Values in Training Data**\n",
        "### **(A) Ignoring Missing Values in Splitting**\n",
        "- Some implementations (like **CART**) allow Decision Trees to **ignore missing values** while finding the best split.\n",
        "- If a feature has missing values, the tree may still use it if it provides the **best impurity reduction**.\n",
        "\n",
        "### **(B) Surrogate Splits (Used in CART)**\n",
        "- If the best feature for a split has missing values, Decision Trees **find an alternative (surrogate) feature** that gives a similar split.\n",
        "- If a missing value is encountered, the tree **follows the surrogate split** instead.\n",
        "\n",
        "### **(C) Assigning Missing Values to the Most Common Category (for Categorical Features)**\n",
        "- If a categorical feature has missing values, the tree can replace them with **the most frequent category** in the training data.\n",
        "\n",
        "### **(D) Assigning Missing Values to the Mean/Median (for Numerical Features)**\n",
        "- If a numerical feature has missing values, it can be replaced with **the mean or median** of that feature.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Handling Missing Values During Prediction**\n",
        "### **(A) Assigning Probabilities Based on Training Splits**\n",
        "- If a missing value is encountered at test time, the tree assigns **a probability** to follow different branches based on the distribution of training data.\n",
        "\n",
        "### **(B) Following the Most Common Path**\n",
        "- Some algorithms choose the **majority branch** (the branch most samples took in training) when encountering missing values.\n",
        "\n",
        "---\n",
        "\n",
        "## **Example: Handling Missing Values in Scikit-Learn**\n",
        "Scikit-Learn does **not** natively handle missing values in Decision Trees, so you must **fill or drop** missing values before training.\n",
        "\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "# Sample dataset with missing values\n",
        "X = np.array([[1, 2], [3, np.nan], [7, 6], [np.nan, 4]])\n",
        "y = np.array([0, 1, 0, 1])\n",
        "\n",
        "# Impute missing values with the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Train Decision Tree\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(X_imputed, y)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **Summary: Best Practices for Handling Missing Values in Decision Trees**\n",
        "| **Method** | **How It Works** | **Pros** | **Cons** |\n",
        "|------------|-----------------|----------|----------|\n",
        "| Ignore missing values | Skips missing data when finding splits | Simple, keeps data | May reduce accuracy |\n",
        "| Surrogate splits | Uses backup features for missing values | Keeps model robust | Increases complexity |\n",
        "| Fill with mode (categorical) | Replaces missing values with most frequent category | Easy, quick | Can bias results |\n",
        "| Fill with mean/median (numerical) | Replaces missing values with mean or median | Keeps all data | May distort distributions |\n",
        "| Assign probabilities | Follows branches probabilistically based on training data | More flexible | Harder to interpret |\n"
      ],
      "metadata": {
        "id": "7Q38zw0UUFbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14.How does a Decision Tree handle categorical features?"
      ],
      "metadata": {
        "id": "mYIQuakzUPZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **How Decision Trees Handle Categorical Features**  \n",
        "\n",
        "Decision Trees can naturally handle **categorical features** by splitting data based on category values. However, the way they handle categorical data depends on the implementation.  \n",
        "\n",
        "---\n",
        "\n",
        "## **1Ô∏è‚É£ Splitting Categorical Features in Decision Trees**  \n",
        "For categorical features, Decision Trees **group data** based on unique categories rather than numeric thresholds.  \n",
        "\n",
        "### **(A) Binary Splitting (Used in CART ‚Äì Scikit-Learn)**\n",
        "- **Works by converting categorical values into 0/1 decisions** (e.g., \"Is Feature = X?\").\n",
        "- If a feature has multiple categories (e.g., Red, Blue, Green), the algorithm finds the best **binary split** (e.g., {Red, Blue} vs. {Green}).\n",
        "- **Example:**\n",
        "  ```\n",
        "  Color Feature: {Red, Blue, Green}\n",
        "  Possible split: {Red, Blue} vs. {Green}\n",
        "  ```\n",
        "- Uses **Gini Impurity** or **Entropy** to determine the best split.\n",
        "\n",
        "‚úî **Pros**: Works well for large datasets.  \n",
        "‚ùå **Cons**: Computationally expensive for high-cardinality categorical variables.  \n",
        "\n",
        "---\n",
        "\n",
        "### **(B) Multiway Splitting (Used in ID3, C4.5)**\n",
        "- Instead of making a binary decision, the tree **creates a branch for each category**.\n",
        "- **Example:**\n",
        "  ```\n",
        "  Feature: Animal Type (Dog, Cat, Bird)\n",
        "  Decision Tree:\n",
        "      Animal Type\n",
        "      ‚îú‚îÄ‚îÄ Dog ‚Üí Class A\n",
        "      ‚îú‚îÄ‚îÄ Cat ‚Üí Class B\n",
        "      ‚îú‚îÄ‚îÄ Bird ‚Üí Class C\n",
        "  ```\n",
        "‚úî **Pros**: More intuitive, no need for numerical encoding.  \n",
        "‚ùå **Cons**: Can lead to **overfitting** if too many categories.  \n",
        "\n",
        "---\n",
        "\n",
        "## **2Ô∏è‚É£ Encoding Categorical Features for Decision Trees**  \n",
        "Some Decision Tree implementations (e.g., **Scikit-Learn‚Äôs `DecisionTreeClassifier`**) do not directly support categorical variables. You must **convert categorical features into numbers** before training.\n",
        "\n",
        "### **(A) Label Encoding (Integer Encoding)**\n",
        "- Assigns a **unique number** to each category.\n",
        "- **Example:**\n",
        "  ```\n",
        "  Color: {Red, Blue, Green} ‚Üí {0, 1, 2}\n",
        "  ```\n",
        "- Works well for **ordinal** data (e.g., Small, Medium, Large).  \n",
        "- **Not ideal for non-ordinal data** (e.g., \"Red\" is not \"greater\" than \"Blue\").  \n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "X['Color'] = encoder.fit_transform(X['Color'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **(B) One-Hot Encoding (OHE)**\n",
        "- Converts categorical values into **binary columns (0s and 1s)**.\n",
        "- **Example:**\n",
        "  ```\n",
        "  Color: {Red, Blue, Green}\n",
        "  ‚Üí Red (1,0,0), Blue (0,1,0), Green (0,0,1)\n",
        "  ```\n",
        "- Prevents the tree from assuming a numeric order in categories.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "X_encoded = encoder.fit_transform(X[['Color']]).toarray()\n",
        "```\n",
        "\n",
        "‚úî **Pros**: Avoids artificial ordering of categories.  \n",
        "‚ùå **Cons**: Can lead to **high-dimensional data** if there are too many unique categories.  \n",
        "\n",
        "---\n",
        "\n",
        "## **3Ô∏è‚É£ Best Practices for Categorical Features in Decision Trees**\n",
        "| **Method**         | **Best For** | **Pros** | **Cons** |\n",
        "|--------------------|-------------|----------|----------|\n",
        "| **Binary Splitting (CART)** | Low-cardinality categorical data | Works well with Gini/Entropy | Computationally expensive for many categories |\n",
        "| **Multiway Splitting (ID3, C4.5)** | Few categories, interpretability | No need for encoding | Overfitting risk if too many categories |\n",
        "| **Label Encoding** | Ordinal categorical data | Simple, easy to use | Implies an artificial order |\n",
        "| **One-Hot Encoding** | Non-ordinal categorical data | Removes order bias | Increases dataset size |\n"
      ],
      "metadata": {
        "id": "p8O_MeW2UTwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15. What are some real-world applications of Decision Trees?"
      ],
      "metadata": {
        "id": "1ZGq-l8MUoUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.### **Real-World Applications of Decision Trees** üåçüå≥  \n",
        "\n",
        "Decision Trees are widely used in various domains due to their simplicity, interpretability, and ability to handle both numerical and categorical data. Here are some key real-world applications:  \n",
        "\n",
        "---\n",
        "\n",
        "## **1Ô∏è‚É£ Healthcare & Medical Diagnosis üè•**  \n",
        "‚úî **Disease Prediction & Diagnosis**  \n",
        "- Decision Trees help predict diseases like **diabetes, cancer, and heart disease** based on patient symptoms and test results.  \n",
        "- Example: A Decision Tree can classify whether a patient has **diabetes** based on **blood sugar levels, age, BMI, and lifestyle factors**.  \n",
        "\n",
        "‚úî **Medical Treatment Plans**  \n",
        "- Doctors use Decision Trees to **recommend personalized treatments** by analyzing patient history.  \n",
        "- Example: Choosing between **surgery, medication, or physical therapy** based on patient symptoms and risk factors.  \n",
        "\n",
        "‚úî **Predicting Disease Outcomes**  \n",
        "- Example: A Decision Tree can estimate the **survival rate of cancer patients** based on tumor size, stage, and genetic factors.  \n",
        "\n",
        "---\n",
        "\n",
        "## **2Ô∏è‚É£ Finance & Banking üí∞**  \n",
        "‚úî **Credit Scoring & Loan Approval**  \n",
        "- Banks use Decision Trees to determine **whether a customer should be approved for a loan** based on factors like **credit score, income, and debt history**.  \n",
        "- Example:  \n",
        "  ```\n",
        "  IF credit score > 700 AND income > $50,000 ‚Üí APPROVE loan\n",
        "  ELSE ‚Üí REJECT loan\n",
        "  ```\n",
        "\n",
        "‚úî **Fraud Detection**  \n",
        "- Helps identify **fraudulent transactions** by analyzing **patterns in credit card usage**.  \n",
        "- Example: If a transaction is **outside the country + unusual spending amount** ‚Üí Mark as suspicious.  \n",
        "\n",
        "‚úî **Stock Market Predictions**  \n",
        "- Decision Trees help **predict stock price movements** based on **historical trends, company earnings, and market conditions**.  \n",
        "\n",
        "---\n",
        "\n",
        "## **3Ô∏è‚É£ E-Commerce & Retail üõí**  \n",
        "‚úî **Customer Churn Prediction**  \n",
        "- Predicts **which customers are likely to stop using a service** based on factors like **purchase frequency, complaints, and subscription history**.  \n",
        "\n",
        "‚úî **Recommendation Systems**  \n",
        "- Helps **recommend products** based on a customer‚Äôs past purchases, demographics, and browsing behavior.  \n",
        "- Example:  \n",
        "  ```\n",
        "  IF customer bought a smartphone ‚Üí Recommend phone cases, chargers\n",
        "  ```\n",
        "\n",
        "‚úî **Pricing Strategies**  \n",
        "- Determines the **best price for a product** based on competitor prices, demand, and customer behavior.  \n",
        "\n",
        "---\n",
        "\n",
        "## **4Ô∏è‚É£ Marketing & Sales üì¢**  \n",
        "‚úî **Customer Segmentation**  \n",
        "- Decision Trees help classify customers into different **segments** (e.g., high-value customers, occasional buyers, one-time shoppers).  \n",
        "\n",
        "‚úî **Lead Scoring & Conversion Prediction**  \n",
        "- Helps **identify potential customers** who are more likely to make a purchase.  \n",
        "- Example:  \n",
        "  ```\n",
        "  IF customer visited product page > 5 times AND added to cart ‚Üí HIGH chance of buying\n",
        "  ```\n",
        "\n",
        "‚úî **Email Marketing Optimization**  \n",
        "- Predicts **which customers are likely to open emails and engage with promotions**.  \n",
        "\n",
        "---\n",
        "\n",
        "## **5Ô∏è‚É£ Manufacturing & Supply Chain ‚öôÔ∏è**  \n",
        "‚úî **Quality Control & Defect Detection**  \n",
        "- Identifies defective products based on **sensor data, machine performance, and production conditions**.  \n",
        "\n",
        "‚úî **Demand Forecasting**  \n",
        "- Predicts future demand for products based on **seasonality, trends, and past sales data**.  \n",
        "\n",
        "‚úî **Inventory Management**  \n",
        "- Helps optimize **stock levels** by predicting when **products will run out**.  \n",
        "\n",
        "---\n",
        "\n",
        "## **6Ô∏è‚É£ Education & Student Performance üìö**  \n",
        "‚úî **Student Performance Prediction**  \n",
        "- Predicts **which students are at risk of failing** based on attendance, grades, and engagement.  \n",
        "\n",
        "‚úî **Personalized Learning Plans**  \n",
        "- Helps design **customized learning programs** based on student strengths and weaknesses.  \n",
        "\n",
        "‚úî **Admission Predictions**  \n",
        "- Predicts **college admission chances** based on SAT scores, GPA, and extracurricular activities.  \n",
        "\n",
        "---\n",
        "\n",
        "## **7Ô∏è‚É£ Energy & Utilities ‚ö°**  \n",
        "‚úî **Power Consumption Prediction**  \n",
        "- Predicts **electricity demand** based on weather, time of day, and consumer usage patterns.  \n",
        "\n",
        "‚úî **Fault Detection in Power Grids**  \n",
        "- Helps detect **equipment failures** in power stations.  \n",
        "\n",
        "‚úî **Optimizing Renewable Energy Usage**  \n",
        "- Decision Trees can decide **when to switch between solar, wind, and grid power** for cost savings.  \n",
        "\n",
        "---\n",
        "\n",
        "## **8Ô∏è‚É£ Transportation & Logistics üöö**  \n",
        "‚úî **Route Optimization for Delivery Services**  \n",
        "- Companies like **Amazon, FedEx, and Uber** use Decision Trees to determine **the fastest and cheapest delivery routes**.  \n",
        "\n",
        "‚úî **Predicting Traffic Congestion**  \n",
        "- Analyzes road conditions, weather, and historical traffic data to **predict traffic jams**.  \n",
        "\n",
        "‚úî **Autonomous Vehicles**  \n",
        "- Helps **self-driving cars** make decisions like **when to stop, turn, or change lanes** based on sensor inputs.  \n",
        "\n",
        "---\n",
        "\n",
        "## **9Ô∏è‚É£ Human Resources & Hiring üë®‚Äçüíº**  \n",
        "‚úî **Resume Screening & Candidate Selection**  \n",
        "- Helps HR teams **shortlist job applicants** based on qualifications, experience, and skillset.  \n",
        "\n",
        "‚úî **Employee Attrition Prediction**  \n",
        "- Predicts **which employees are likely to leave** based on job satisfaction, salary, and workload.  \n",
        "\n",
        "‚úî **Performance Evaluation & Promotions**  \n",
        "- Helps decide **which employees should be promoted** based on performance metrics.  \n",
        "\n",
        "---\n",
        "\n",
        "### **üîπ Summary: Why Use Decision Trees in Real-World Applications?**  \n",
        "\n",
        "| **Industry**          | **Application**                                      |\n",
        "|----------------------|------------------------------------------------------|\n",
        "| **Healthcare**       | Disease diagnosis, treatment plans, risk prediction |\n",
        "| **Finance**         | Loan approval, fraud detection, credit scoring |\n",
        "| **E-commerce**      | Customer segmentation, recommendation systems |\n",
        "| **Marketing**       | Lead scoring, email marketing optimization |\n",
        "| **Manufacturing**   | Defect detection, supply chain optimization |\n",
        "| **Education**       | Student performance prediction, admission chances |\n",
        "| **Energy**         | Power consumption prediction, renewable energy use |\n",
        "| **Transportation**  | Route optimization, self-driving car decisions |\n",
        "| **HR & Hiring**     | Resume screening, employee attrition prediction |\n"
      ],
      "metadata": {
        "id": "sslJ_aQ0UtO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Practical**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VNzGyzGoU9lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16.Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy?"
      ],
      "metadata": {
        "id": "uLRejBYOVGPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Decision Tree Classifier model\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print accuracy\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS8lfy-TVbwr",
        "outputId": "a2692ed3-2838-47b7-ed56-eb143738b3f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17.Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the\n",
        "feature importances?"
      ],
      "metadata": {
        "id": "X4xR7wf_V6V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Decision Tree Classifier with Gini Impurity\n",
        "clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print feature importances\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature, importance in zip(iris.feature_names, clf.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCTSoXjdWD4R",
        "outputId": "dd00b190-9f84-47e5-e1ad-be5dc0623ef8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n",
            "\n",
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0167\n",
            "petal length (cm): 0.9061\n",
            "petal width (cm): 0.0772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18.Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the\n",
        "model accuracy?"
      ],
      "metadata": {
        "id": "dONVmSc9WQf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Decision Tree Classifier with Entropy\n",
        "clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAQQux6zWbSl",
        "outputId": "e2dd7313-c264-4f13-bd8e-29b8e5ce158e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q19.Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean\n",
        "Squared Error (MSE)?"
      ],
      "metadata": {
        "id": "LhBDL72kW5vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target  # Features and target variable\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Decision Tree Regressor model\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg4nd8L_XH1n",
        "outputId": "f2ddf167-dd66-40b7-e761-c17b2f6ed5ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.4952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20.Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz?"
      ],
      "metadata": {
        "id": "NHe_zJbKXTqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "clf.fit(X, y)  # Training the model on the full dataset\n",
        "\n",
        "# Export the tree to Graphviz format\n",
        "dot_data = export_graphviz(clf, out_file=None,\n",
        "                           feature_names=iris.feature_names,\n",
        "                           class_names=iris.target_names,\n",
        "                           filled=True, rounded=True, special_characters=True)\n",
        "\n",
        "# Visualize the decision tree\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree\")  # Saves as decision_tree.pdf\n",
        "graph.view()  # Opens the visualization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "collapsed": true,
        "id": "5nF58AUUXalp",
        "outputId": "c7541c0c-18b9-4c2a-d8ea-dbe6c077b2c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'decision_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21.Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its\n",
        "accuracy with a fully grown tree?"
      ],
      "metadata": {
        "id": "2iAAM799XnpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier with max depth of 3\n",
        "clf_limited = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf_limited.fit(X_train, y_train)\n",
        "\n",
        "# Train a fully grown Decision Tree (no depth restriction)\n",
        "clf_full = DecisionTreeClassifier(random_state=42)\n",
        "clf_full.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_limited = clf_limited.predict(X_test)\n",
        "y_pred_full = clf_full.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_limited = accuracy_score(y_test, y_pred_limited)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "# Print the accuracy comparison\n",
        "print(f\"Accuracy with max depth = 3: {accuracy_limited:.2f}\")\n",
        "print(f\"Accuracy with fully grown tree: {accuracy_full:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPBaymfYXuTf",
        "outputId": "6b708908-d62a-4cd5-a826-8edb1c03c881"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with max depth = 3: 1.00\n",
            "Accuracy with fully grown tree: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q22.* Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its\n",
        "accuracy with a default tree?"
      ],
      "metadata": {
        "id": "rJB-fMEiX31V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier with min_samples_split=5\n",
        "clf_restricted = DecisionTreeClassifier(min_samples_split=5, random_state=42)\n",
        "clf_restricted.fit(X_train, y_train)\n",
        "\n",
        "# Train a fully grown Decision Tree (default parameters)\n",
        "clf_default = DecisionTreeClassifier(random_state=42)\n",
        "clf_default.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_restricted = clf_restricted.predict(X_test)\n",
        "y_pred_default = clf_default.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_restricted = accuracy_score(y_test, y_pred_restricted)\n",
        "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
        "\n",
        "# Print the accuracy comparison\n",
        "print(f\"Accuracy with min_samples_split=5: {accuracy_restricted:.2f}\")\n",
        "print(f\"Accuracy with default tree: {accuracy_default:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNP7eebbYi-L",
        "outputId": "c20911a5-b908-4942-c090-3f588a9b3fc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with min_samples_split=5: 1.00\n",
            "Accuracy with default tree: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23.Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its\n",
        "accuracy with unscaled data?"
      ],
      "metadata": {
        "id": "WalE0ggDYyqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier without feature scaling\n",
        "clf_unscaled = DecisionTreeClassifier(random_state=42)\n",
        "clf_unscaled.fit(X_train, y_train)\n",
        "y_pred_unscaled = clf_unscaled.predict(X_test)\n",
        "accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
        "\n",
        "# Apply feature scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a Decision Tree Classifier with scaled features\n",
        "clf_scaled = DecisionTreeClassifier(random_state=42)\n",
        "clf_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = clf_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print accuracy comparison\n",
        "print(f\"Accuracy without scaling: {accuracy_unscaled:.2f}\")\n",
        "print(f\"Accuracy with feature scaling: {accuracy_scaled:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgDRA3IiZEUO",
        "outputId": "bbeb6a75-863c-495b-8b06-a5286621821a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.00\n",
            "Accuracy with feature scaling: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24.* Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass\n",
        "classification?"
      ],
      "metadata": {
        "id": "1nit50WuZHsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target  # Features and target labels\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Decision Tree Classifier wrapped in One-vs-Rest (OvR)\n",
        "clf_ovr = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
        "clf_ovr.fit(X_train, y_train)  # Train the model\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf_ovr.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Model Accuracy using One-vs-Rest (OvR): {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9Apv7E9ZOJ1",
        "outputId": "5fc3dad1-79c0-42aa-a055-56db548f1c14"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy using One-vs-Rest (OvR): 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25. Write a Python program to train a Decision Tree Classifier and display the feature importance scores?"
      ],
      "metadata": {
        "id": "evp29VG0Zb6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Display feature importance scores\n",
        "print(\"\\nFeature Importance Scores:\")\n",
        "for feature, importance in zip(iris.feature_names, clf.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSEF66NUZrDe",
        "outputId": "506d6aef-69f4-41f6-9ee5-271cc2f30f52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n",
            "\n",
            "Feature Importance Scores:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0167\n",
            "petal length (cm): 0.9061\n",
            "petal width (cm): 0.0772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q26.Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance\n",
        "with an unrestricted tree?"
      ],
      "metadata": {
        "id": "icvQ2npVZ4Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target  # Features and target variable\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Regressor with max depth = 5\n",
        "regressor_limited = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "regressor_limited.fit(X_train, y_train)\n",
        "\n",
        "# Train a fully grown Decision Tree Regressor (default settings)\n",
        "regressor_full = DecisionTreeRegressor(random_state=42)\n",
        "regressor_full.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_limited = regressor_limited.predict(X_test)\n",
        "y_pred_full = regressor_full.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse_limited = mean_squared_error(y_test, y_pred_limited)\n",
        "mse_full = mean_squared_error(y_test, y_pred_full)\n",
        "\n",
        "# Print the performance comparison\n",
        "print(f\"Mean Squared Error (MSE) with max_depth=5: {mse_limited:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE) with fully grown tree: {mse_full:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwJ9pd6baJxY",
        "outputId": "a030bf15-f31e-48c6-a37e-0a5ee4f2644f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) with max_depth=5: 0.5245\n",
            "Mean Squared Error (MSE) with fully grown tree: 0.4952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q27.Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and\n",
        "visualize its effect on accuracy?"
      ],
      "metadata": {
        "id": "TSImftLbaTGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a fully grown Decision Tree Classifier\n",
        "clf_full = DecisionTreeClassifier(random_state=42)\n",
        "clf_full.fit(X_train, y_train)\n",
        "\n",
        "# Get cost complexity pruning path\n",
        "ccp_path = clf_full.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = ccp_path.ccp_alphas[:-1]  # Ignore the last max alpha that prunes all nodes\n",
        "\n",
        "# Train models for each alpha and collect accuracies\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for alpha in ccp_alphas:\n",
        "    clf_pruned = DecisionTreeClassifier(random_state=42, ccp_alpha=alpha)\n",
        "    clf_pruned.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate accuracy on training and test data\n",
        "    train_accuracies.append(accuracy_score(y_train, clf_pruned.predict(X_train)))\n",
        "    test_accuracies.append(accuracy_score(y_test, clf_pruned.predict(X_test)))\n",
        "\n",
        "# Plot accuracy vs. CCP alpha\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(ccp_alphas, train_accuracies, marker=\"o\", label=\"Training Accuracy\")\n",
        "plt.plot(ccp_alphas, test_accuracies, marker=\"o\", label=\"Testing Accuracy\")\n",
        "plt.xlabel(\"CCP Alpha (Pruning Strength)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Effect of Cost Complexity Pruning on Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "PHDWFPMRaX1v",
        "outputId": "8131ee78-fbc3-4a8e-ddd4-00c85b4e16cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q28.Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision,\n",
        "Recall, and F1-Score?"
      ],
      "metadata": {
        "id": "ozYyrSSIaij5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4lXPGtaan9u",
        "outputId": "7e572897-b87f-4b81-8752-575a75cb0ecd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q29.Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn?"
      ],
      "metadata": {
        "id": "56MwdN9zayUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Visualize the confusion matrix using seaborn\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "p4woSwHea251",
        "outputId": "5159bf4b-b4e7-4ed3-c1cc-d18625460f40"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q30.Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values\n",
        "for max_depth and min_samples_split?"
      ],
      "metadata": {
        "id": "GV7ELUs6bBVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 10, None],  # Different depths including unrestricted tree\n",
        "    'min_samples_split': [2, 5, 10]  # Minimum samples to split a node\n",
        "}\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Train a Decision Tree using the best parameters\n",
        "best_clf = grid_search.best_estimator_\n",
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Best Parameters: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReasOx_tbHSy",
        "outputId": "e2cffb04-6ec8-4f57-f74f-34375de03657"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 10, 'min_samples_split': 2}\n",
            "Model Accuracy with Best Parameters: 1.00\n"
          ]
        }
      ]
    }
  ]
}